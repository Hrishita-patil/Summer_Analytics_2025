{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQdDgWm-ReJT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Combine 'LastUpdatedDate' and 'LastUpdatedTime' columns into a single 'timestamp' column\n",
        "# Format is specified to ensure correct datetime parsing\n",
        "df['timestamp'] = pd.to_datetime(\n",
        "    df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'],\n",
        "    format='%d-%m-%Y %H:%M:%S'\n",
        ")\n",
        "\n",
        "# Map traffic condition levels from categorical to numerical values for modeling\n",
        "traffic_map = {'low': 1, 'medium': 2, 'high': 3}\n",
        "df['TrafficLevel'] = df['TrafficConditionNearby'].map(traffic_map)\n",
        "\n",
        "# Convert the 'VehicleType' column into one-hot encoded dummy variables\n",
        "vehicle_dummies = pd.get_dummies(df['VehicleType'], prefix='Vehicle')\n",
        "\n",
        "# Append the dummy variables to the original DataFrame\n",
        "df = pd.concat([df, vehicle_dummies], axis=1)\n",
        "\n",
        "# Drop columns that have been processed and are no longer needed\n",
        "df.drop(columns=['LastUpdatedDate', 'LastUpdatedTime', 'TrafficConditionNearby', 'VehicleType'], inplace=True)\n",
        "\n",
        "# Check for missing values in the dataset and print the count per column\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "\n",
        "# Remove duplicate rows from the dataset, if any\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Sort the DataFrame by parking lot and timestamp to maintain chronological order\n",
        "df.sort_values(by=['SystemCodeNumber', 'timestamp'], inplace=True)\n",
        "\n",
        "# Reset the index to reflect the new ordering after sorting\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the first few rows of the processed DataFrame for quick inspection\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the raw dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Combine and convert date and time columns into a single ISO-formatted timestamp\n",
        "df['timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'], format='%d-%m-%Y %H:%M:%S')\n",
        "df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%dT%H:%M:%S')  # Format to ISO 8601\n",
        "\n",
        "# Map traffic conditions to numerical values\n",
        "traffic_map = {'low': 1, 'medium': 2, 'high': 3}\n",
        "df['TrafficLevel'] = df['TrafficConditionNearby'].map(traffic_map)\n",
        "df['TrafficLevel'] = df['TrafficLevel'].fillna(0).astype(int)  # Replace missing with 0\n",
        "\n",
        "# Convert 'VehicleType' categorical column into dummy variables\n",
        "vehicle_dummies = pd.get_dummies(df['VehicleType'], prefix='Vehicle')\n",
        "df = pd.concat([df, vehicle_dummies], axis=1)\n",
        "\n",
        "# Ensure all expected dummy columns are present, even if missing in input\n",
        "for col in ['Vehicle_car', 'Vehicle_bike', 'Vehicle_truck']:\n",
        "    if col not in df:\n",
        "        df[col] = 0\n",
        "\n",
        "# Drop raw categorical and now redundant columns\n",
        "df.drop(columns=['LastUpdatedDate', 'LastUpdatedTime', 'TrafficConditionNearby', 'VehicleType'], inplace=True)\n",
        "\n",
        "# Fill missing values in integer columns with 0 and ensure correct type\n",
        "int_columns = ['Capacity', 'Occupancy', 'QueueLength', 'IsSpecialDay', 'TrafficLevel',\n",
        "               'Vehicle_car', 'Vehicle_bike', 'Vehicle_truck']\n",
        "df[int_columns] = df[int_columns].fillna(0).astype(int)\n",
        "\n",
        "# Remove any duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Sort the dataset chronologically within each parking lot\n",
        "df.sort_values(by=['SystemCodeNumber', 'timestamp'], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save the cleaned and formatted dataset for use in dynamic pricing models\n",
        "df.to_csv(\"parking_stream.csv\", index=False)\n",
        "\n",
        "# Display sample of the cleaned dataset\n",
        "print(\"Cleaned data ready for streaming:\\n\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "Ni6bDJQuRiXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Urban Parking Dynamic Pricing – Model 1 (Baseline) Using Pathway\n",
        "\n",
        "This script simulates real-time dynamic pricing for urban parking using a baseline occupancy-based model,\n",
        "executed via the Pathway real-time data processing engine.\n",
        "\n",
        "The baseline pricing logic increases the parking fee linearly with occupancy using the formula:\n",
        "    price = BASE_PRICE + ALPHA × (occupancy / capacity)\n",
        "\n",
        "Key Steps:\n",
        "1. Preprocess the raw parking dataset and encode features.\n",
        "2. Simulate a streaming environment using Pathway with a subset of data.\n",
        "3. Define a simple pricing function based on occupancy ratio.\n",
        "4. Stream processed data through the model and output results to CSV."
      ],
      "metadata": {
        "id": "3Qs4pUzKRuMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pathway as pw\n",
        "from pathway.internals.dtype import DATE_TIME_NAIVE\n",
        "from datetime import datetime\n",
        "\n",
        "# --- STEP 1: Data Preprocessing ---\n",
        "\n",
        "# Load full raw dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Combine date and time columns into ISO timestamp format\n",
        "df['timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'], format='%d-%m-%Y %H:%M:%S')\n",
        "df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "\n",
        "# Map traffic condition to numeric levels (low=1, medium=2, high=3)\n",
        "traffic_map = {'low': 1, 'medium': 2, 'high': 3}\n",
        "df['TrafficLevel'] = df['TrafficConditionNearby'].map(traffic_map)\n",
        "df['TrafficLevel'] = df['TrafficLevel'].fillna(0).astype(int)\n",
        "\n",
        "# One-hot encode 'VehicleType' into separate binary columns\n",
        "vehicle_dummies = pd.get_dummies(df['VehicleType'], prefix='Vehicle')\n",
        "df = pd.concat([df, vehicle_dummies], axis=1)\n",
        "\n",
        "# Ensure consistent schema by adding missing dummy columns if needed\n",
        "for col in ['Vehicle_car', 'Vehicle_bike', 'Vehicle_truck']:\n",
        "    if col not in df:\n",
        "        df[col] = 0\n",
        "\n",
        "# Drop columns no longer required after encoding and timestamp creation\n",
        "df.drop(columns=['LastUpdatedDate', 'LastUpdatedTime', 'TrafficConditionNearby', 'VehicleType'], inplace=True)\n",
        "\n",
        "# Convert all necessary columns to integers, filling any missing values with 0\n",
        "int_cols = ['Capacity', 'Occupancy', 'QueueLength', 'IsSpecialDay', 'TrafficLevel',\n",
        "            'Vehicle_car', 'Vehicle_bike', 'Vehicle_truck']\n",
        "df[int_cols] = df[int_cols].fillna(0).astype(int)\n",
        "\n",
        "# Limit data to 1 parking lot (first in the list) and first 200 records to simulate streaming\n",
        "lot = df['SystemCodeNumber'].unique()[0]\n",
        "df_small = df[df['SystemCodeNumber'] == lot].head(200).copy()\n",
        "\n",
        "# Save this subset for use in Pathway streaming\n",
        "df_small.to_csv(\"parking_stream.csv\", index=False)\n",
        "print(f\"Saved subset for {lot} with {len(df_small)} rows.\")\n",
        "\n",
        "# --- STEP 2: Define Pathway Schema ---\n",
        "# Schema defines data structure for the stream\n",
        "class ParkingStream(pw.Schema):\n",
        "    timestamp: DATE_TIME_NAIVE\n",
        "    SystemCodeNumber: str\n",
        "    Capacity: int\n",
        "    Occupancy: int\n",
        "    QueueLength: int\n",
        "    IsSpecialDay: int\n",
        "    TrafficLevel: int\n",
        "    Vehicle_bike: int\n",
        "    Vehicle_car: int\n",
        "    Vehicle_truck: int\n",
        "\n",
        "# --- STEP 3: Read Streaming Data ---\n",
        "# Load the CSV as a static stream (change to \"streaming\" for live input)\n",
        "stream = pw.io.csv.read(\n",
        "    \"parking_stream.csv\",\n",
        "    schema=ParkingStream,\n",
        "    # mode=\"streaming\",\n",
        "    # autocommit_duration_ms=10  # Optional: controls commit frequency in streaming mode\n",
        ")\n",
        "\n",
        "# --- STEP 4: Baseline Pricing Model ---\n",
        "# Define constants for pricing formula\n",
        "BASE_PRICE = 10.0\n",
        "ALPHA = 2.0\n",
        "MIN_PRICE = 5.0\n",
        "MAX_PRICE = 20.0\n",
        "\n",
        "# Define user-defined function for baseline pricing based on occupancy ratio\n",
        "@pw.udf\n",
        "def baseline_price_fn(occupancy, capacity):\n",
        "    return max(MIN_PRICE, min(MAX_PRICE, BASE_PRICE + ALPHA * (occupancy / capacity)))\n",
        "\n",
        "# --- STEP 5: Apply Pricing Formula ---\n",
        "# Apply pricing logic and extract relevant fields\n",
        "pricing = stream.select(\n",
        "    timestamp=stream.timestamp,\n",
        "    lot=stream.SystemCodeNumber,\n",
        "    price=baseline_price_fn(stream.Occupancy, stream.Capacity)\n",
        ")\n",
        "\n",
        "# --- STEP 6: Export Result ---\n",
        "# Write the result to an output CSV\n",
        "pw.io.csv.write(pricing, \"baseline_output.csv\")\n",
        "\n",
        "# --- STEP 7: Run Pathway Application ---\n",
        "pw.run()\n"
      ],
      "metadata": {
        "id": "N_5DvAuFRoI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules from Bokeh for interactive plotting\n",
        "from bokeh.plotting import figure, curdoc\n",
        "from bokeh.models import ColumnDataSource, Select\n",
        "from bokeh.layouts import column\n",
        "import pandas as pd\n",
        "\n",
        "# --- Step 1: Load and preprocess the dataset ---\n",
        "\n",
        "# Load the raw dataset from CSV\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Combine the date and time columns into a single datetime object\n",
        "df['timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'], format='%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "# Drop the original date and time columns as they're now redundant\n",
        "df.drop(columns=['LastUpdatedDate', 'LastUpdatedTime'], inplace=True)\n",
        "\n",
        "# --- Step 2: Define baseline model parameters ---\n",
        "\n",
        "BASE_PRICE = 10.0   # Starting base price\n",
        "ALPHA = 2.0         # Sensitivity to occupancy\n",
        "MIN_PRICE = 5.0     # Minimum allowed price\n",
        "MAX_PRICE = 20.0    # Maximum allowed price\n",
        "\n",
        "# --- Step 3: Define a function to compute dynamic price per lot ---\n",
        "\n",
        "def compute_price(data):\n",
        "    \"\"\"\n",
        "    Applies the baseline dynamic pricing model to a single lot's data,\n",
        "    adjusting price based on occupancy over time.\n",
        "    \"\"\"\n",
        "    data = data.sort_values(by='timestamp').copy()\n",
        "    data['Price'] = BASE_PRICE  # Start with base price\n",
        "\n",
        "    for i in range(1, len(data)):\n",
        "        prev = data.iloc[i-1]  # Previous row\n",
        "        occ = data.iloc[i]['Occupancy']\n",
        "        cap = data.iloc[i]['Capacity']\n",
        "        # Update price based on previous value and occupancy ratio\n",
        "        data.at[data.index[i], 'Price'] = max(MIN_PRICE, min(MAX_PRICE, prev['Price'] + ALPHA * (occ / cap)))\n",
        "\n",
        "    return data\n",
        "\n",
        "# --- Step 4: Prepare data for all parking lots ---\n",
        "\n",
        "# Get list of all unique lot IDs\n",
        "lots = df['SystemCodeNumber'].unique()\n",
        "\n",
        "# Compute price data for each lot\n",
        "lot_data = {lot: compute_price(df[df['SystemCodeNumber'] == lot]) for lot in lots}\n",
        "\n",
        "# Convert each lot's data to a Bokeh-compatible ColumnDataSource\n",
        "sources = {lot: ColumnDataSource(lot_data[lot]) for lot in lots}\n",
        "\n",
        "# Select the first lot as the default view\n",
        "default_lot = lots[0]\n",
        "source = sources[default_lot]\n",
        "\n",
        "# --- Step 5: Create the Bokeh plot figure ---\n",
        "\n",
        "p = figure(\n",
        "    x_axis_type='datetime',\n",
        "    title=f\"Dynamic Pricing - {default_lot}\",\n",
        "    width=900,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "# Plot price over time for the default lot\n",
        "p.line(x='timestamp', y='Price', source=source, line_width=2)\n",
        "\n",
        "# --- Step 6: Create dropdown widget for lot selection ---\n",
        "\n",
        "lot_selector = Select(title=\"Select Parking Lot:\", value=default_lot, options=list(lots))\n",
        "\n",
        "# Callback function that updates the plot when dropdown value changes\n",
        "def update_plot(attr, old, new):\n",
        "    lot = lot_selector.value  # Get selected lot\n",
        "    source.data = sources[lot].data  # Update data source\n",
        "    p.title.text = f\"Dynamic Pricing - {lot}\"  # Update plot title\n",
        "\n",
        "# Link dropdown changes to the callback function\n",
        "lot_selector.on_change('value', update_plot)\n",
        "\n",
        "# --- Step 7: Set up layout and run app ---\n",
        "\n",
        "layout = column(lot_selector, p)  # Stack dropdown and plot vertically\n",
        "curdoc().add_root(layout)         # Add layout to the document\n",
        "curdoc().title = \"Model 1 Pricing\"  # Set the title of the Bokeh app\n"
      ],
      "metadata": {
        "id": "c08cE1X4SX66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# MODEL 2:\n",
        "Demand-Based Pricing using Pathway\n",
        "This script reads a batch of parking data from CSV,\n",
        "applies a demand-based dynamic pricing formula,\n",
        "and saves the output prices to a CSV file.\n"
      ],
      "metadata": {
        "id": "2m7VK7VUSpNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import pathway as pw\n",
        "from pathway.internals.dtype import DATE_TIME_NAIVE\n",
        "from datetime import datetime\n",
        "\n",
        "# Step 1: Data is assumed to be preprocessed and saved as 'parking_stream.csv'\n",
        "# (See earlier preprocessing script for steps to generate this file)\n",
        "\n",
        "# Step 2: Define Schema for the streaming/batch data\n",
        "# This schema outlines the structure of the data we expect from the CSV\n",
        "class ParkingStream(pw.Schema):\n",
        "    timestamp: DATE_TIME_NAIVE        # Cleaned timestamp\n",
        "    SystemCodeNumber: str             # Parking lot identifier\n",
        "    Capacity: int                     # Total capacity of the lot\n",
        "    Occupancy: int                    # Current occupancy\n",
        "    QueueLength: int                  # Number of vehicles in queue\n",
        "    IsSpecialDay: int                 # Whether it's a special day (1/0)\n",
        "    TrafficLevel: int                 # Encoded traffic condition nearby\n",
        "    Vehicle_bike: int                 # Dummy variable (from one-hot encoding)\n",
        "    Vehicle_car: int                  # Dummy variable (from one-hot encoding)\n",
        "    Vehicle_truck: int                # Dummy variable (from one-hot encoding)\n",
        "\n",
        "# Step 3: Read the CSV data in **batch mode**\n",
        "# Not using real-time streaming here, just processing one batch\n",
        "stream = pw.io.csv.read(\n",
        "    \"parking_stream.csv\",            # Preprocessed input file\n",
        "    schema=ParkingStream             # Use the schema defined above\n",
        ")\n",
        "\n",
        "# Step 4: Define demand-based dynamic pricing logic\n",
        "# We use several features to determine price dynamically\n",
        "BASE_PRICE = 10.0                    # Base starting price\n",
        "ALPHA = 2.0                          # Factor for occupancy effect\n",
        "BETA = 1.5                           # Factor for queue length effect\n",
        "GAMMA = 0.5                          # Factor for traffic level\n",
        "DELTA = 1.0                          # Add-on if it's a special day\n",
        "MIN_PRICE = 5.0                      # Price floor\n",
        "MAX_PRICE = 30.0                     # Price ceiling\n",
        "\n",
        "# Define user-defined function (UDF) to compute price\n",
        "@pw.udf\n",
        "def demand_price_fn(occ, cap, qlen, traffic, special):\n",
        "    # Compute raw price using weighted influence of features\n",
        "    raw_price = (\n",
        "        BASE_PRICE\n",
        "        + ALPHA * (occ / cap)\n",
        "        + BETA * (qlen / cap)\n",
        "        + GAMMA * traffic\n",
        "        + DELTA * special\n",
        "    )\n",
        "    # Clip the price to stay within bounds\n",
        "    return max(MIN_PRICE, min(MAX_PRICE, raw_price))\n",
        "\n",
        "# Step 5: Apply the demand-based model to each record\n",
        "pricing = stream.select(\n",
        "    timestamp=stream.timestamp,\n",
        "    lot=stream.SystemCodeNumber,\n",
        "    price=demand_price_fn(\n",
        "        stream.Occupancy,\n",
        "        stream.Capacity,\n",
        "        stream.QueueLength,\n",
        "        stream.TrafficLevel,\n",
        "        stream.IsSpecialDay\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 6: Output results to CSV\n",
        "# This is a one-time output for the batch data (not continuously updated)\n",
        "pw.io.csv.write(pricing, \"model2_demand_output.csv\")\n",
        "\n",
        "# Step 7: Run the Pathway pipeline to execute the transformations\n",
        "pw.run()\n"
      ],
      "metadata": {
        "id": "vSNJzceqSZVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model Comparison Plot with Annotations\n",
        "This script compares Model 1 (Baseline) and Model 2 (Demand-Based)\n",
        "by plotting their pricing outputs over time for a single parking lot.\n",
        "It also highlights the top 3 highest prices from Model 2.\n"
      ],
      "metadata": {
        "id": "fOc4jumxTN2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load pricing outputs from both models\n",
        "df_model1 = pd.read_csv(\"baseline_output.csv\")\n",
        "df_model2 = pd.read_csv(\"model2_demand_output.csv\")\n",
        "\n",
        "# Convert 'timestamp' column to datetime format for proper plotting\n",
        "df_model1[\"timestamp\"] = pd.to_datetime(df_model1[\"timestamp\"])\n",
        "df_model2[\"timestamp\"] = pd.to_datetime(df_model2[\"timestamp\"])\n",
        "\n",
        "# Filter for a single parking lot (ensures fair comparison)\n",
        "lot = \"BHMBCCMKT01\"\n",
        "df_model1 = df_model1[df_model1[\"lot\"] == lot].sort_values(\"timestamp\")\n",
        "df_model2 = df_model2[df_model2[\"lot\"] == lot].sort_values(\"timestamp\")\n",
        "\n",
        "# Identify top 3 highest price points in Model 2 for annotation\n",
        "top_prices = df_model2.sort_values(\"price\", ascending=False).head(3)\n",
        "\n",
        "# Create a line plot comparing prices from both models\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df_model1[\"timestamp\"], df_model1[\"price\"], label=\"Model 1 (Baseline)\", marker=\"o\")\n",
        "plt.plot(df_model2[\"timestamp\"], df_model2[\"price\"], label=\"Model 2 (Demand-Based)\", marker=\"x\")\n",
        "\n",
        "# Annotate top 3 price spikes in Model 2\n",
        "for idx, row in top_prices.iterrows():\n",
        "    plt.annotate(\n",
        "        f\"${row['price']:.2f}\",                # Text to display\n",
        "        (row[\"timestamp\"], row[\"price\"]),      # Location of the point\n",
        "        textcoords=\"offset points\",            # Position relative to point\n",
        "        xytext=(0, 10),                        # Offset above the point\n",
        "        ha='center',                           # Text alignment\n",
        "        fontsize=9,\n",
        "        color='red',\n",
        "        arrowprops=dict(arrowstyle='->', color='gray')  # Arrow pointing to the point\n",
        "    )\n",
        "\n",
        "# Final plot formatting\n",
        "plt.title(f\"Model Comparison with Annotations for {lot}\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price ($)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping\n",
        "plt.show()          # Display the plot\n"
      ],
      "metadata": {
        "id": "jAtMrcHATOf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model 3: Geo + Demand-Based Dynamic Pricing Model\n",
        "This script estimates dynamic parking prices by\n",
        "incorporating both local lot occupancy and neighboring lot demand."
      ],
      "metadata": {
        "id": "IrtcXT5TXSxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import pathway as pw\n",
        "from geopy.distance import geodesic  # Used to compute distance between GPS coordinates\n",
        "\n",
        "# --- STEP 1: Define a user-defined function to compute geographic distance (in kilometers)\n",
        "@pw.udf\n",
        "def geo_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
        "    return geodesic((lat1, lon1), (lat2, lon2)).km\n",
        "\n",
        "# --- STEP 2: Define the input schema structure for the parking stream\n",
        "class ParkingStream(pw.Schema):\n",
        "    timestamp: str\n",
        "    SystemCodeNumber: str\n",
        "    Occupancy: int\n",
        "    Capacity: int\n",
        "    Latitude: float\n",
        "    Longitude: float\n",
        "\n",
        "# --- STEP 3: Read a static stream (CSV input) using Pathway\n",
        "stream = pw.io.csv.read(\"model3_sample.csv\", schema=ParkingStream, mode=\"static\")\n",
        "\n",
        "# --- STEP 4: Create a self-join of the dataset to compare each lot to all others\n",
        "# This allows calculating pairwise distances between all parking lots\n",
        "stream_copy = stream.copy()\n",
        "raw_neighbors = stream.join(stream_copy, how=pw.JoinMode.INNER).select(\n",
        "    lot=stream.SystemCodeNumber,\n",
        "    neighbor=stream_copy.SystemCodeNumber,\n",
        "    dist=geo_distance(  # Calculate distance between original and copied stream records\n",
        "        stream.Latitude, stream.Longitude,\n",
        "        stream_copy.Latitude, stream_copy.Longitude\n",
        "    ),\n",
        "    occ=stream_copy.Occupancy,  # Occupancy of neighbor lot\n",
        "    cap=stream_copy.Capacity    # Capacity of neighbor lot\n",
        ")\n",
        "\n",
        "# --- STEP 5: Filter out the same lot (self-joins) and keep only neighbors within 1km\n",
        "neighbors = raw_neighbors.filter(\n",
        "    (raw_neighbors.lot != raw_neighbors.neighbor) & (raw_neighbors.dist < 1.0)\n",
        ")\n",
        "\n",
        "# --- STEP 6: (Optional) Save neighbors to CSV for debugging\n",
        "pw.io.csv.write(neighbors, \"model3_neighbors_debug.csv\")\n",
        "\n",
        "# --- STEP 7: Aggregate demand from neighboring lots\n",
        "# Computes the sum of occupancy ratios of nearby lots per lot\n",
        "neighbor_demand = neighbors.groupby(neighbors.lot).reduce(\n",
        "    neighbors.lot,\n",
        "    nearby_demand=pw.reducers.sum(neighbors.occ / neighbors.cap)\n",
        ")\n",
        "\n",
        "# (Optional) Save neighbor demand table for debugging\n",
        "pw.io.csv.write(neighbor_demand, \"model3_neighbor_demand_debug.csv\")\n",
        "\n",
        "# --- STEP 8: Define dynamic pricing function based on:\n",
        "# - Current occupancy\n",
        "# - Capacity\n",
        "# - Total nearby demand (from nearby lots)\n",
        "BASE_PRICE = 5.0\n",
        "\n",
        "@pw.udf\n",
        "def dynamic_price_fn(occ: int, cap: int, nearby_demand: float) -> float:\n",
        "    if cap == 0:\n",
        "        return BASE_PRICE  # Avoid division by zero\n",
        "    occ_ratio = occ / cap\n",
        "    # Final price = base adjusted by own occupancy and half of nearby demand\n",
        "    return round(BASE_PRICE * (1 + occ_ratio + 0.5 * nearby_demand), 2)\n",
        "\n",
        "# --- STEP 9: Join stream with neighbor demand based on SystemCodeNumber\n",
        "joined = stream.join(neighbor_demand, stream.SystemCodeNumber == neighbor_demand.lot, how=pw.JoinMode.LEFT)\n",
        "\n",
        "# --- STEP 10: Apply pricing function, replacing missing neighbor demand with 0\n",
        "enriched = joined.select(\n",
        "    timestamp=joined.timestamp,\n",
        "    lot=joined.SystemCodeNumber,\n",
        "    price=dynamic_price_fn(\n",
        "        joined.Occupancy,\n",
        "        joined.Capacity,\n",
        "        pw.coalesce(joined.nearby_demand, 0.0)  # Use 0 if no neighbors found\n",
        "    )\n",
        ")\n",
        "\n",
        "# --- STEP 11: Format final output columns\n",
        "final_output = enriched.select(\n",
        "    timestamp=enriched.timestamp,\n",
        "    SystemCodeNumber=enriched.lot,\n",
        "    price=enriched.price\n",
        ")\n",
        "\n",
        "# --- Optional Debugging Outputs: Save the keys used in join for validation\n",
        "pw.io.csv.write(stream.select(code=stream.SystemCodeNumber), \"debug_keys_stream.csv\")\n",
        "pw.io.csv.write(neighbor_demand.select(code=neighbor_demand.lot), \"debug_keys_neighbors.csv\")\n",
        "\n",
        "# --- STEP 12: Write final output of Model 3 to CSV\n",
        "pw.io.csv.write(final_output, \"model3_output.csv\")\n",
        "\n",
        "# --- STEP 13: Execute the Pathway data pipeline\n",
        "pw.run()\n"
      ],
      "metadata": {
        "id": "ibeHp0yVTW_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Compare Baseline Model (Model 1) with Model 3\n",
        "This script merges the pricing outputs of both models\n",
        "and computes the difference in predicted prices\n"
      ],
      "metadata": {
        "id": "LJvzUepXXk85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load pricing outputs from both models\n",
        "baseline_df = pd.read_csv(\"baseline_output.csv\")   # Output from Model 1\n",
        "model3_df = pd.read_csv(\"model3_output.csv\")       # Output from Model 3\n",
        "\n",
        "# Rename 'lot' column to 'SystemCodeNumber' in baseline_df\n",
        "# to ensure both DataFrames can be merged correctly\n",
        "baseline_df = baseline_df.rename(columns={\"lot\": \"SystemCodeNumber\"})\n",
        "\n",
        "# Merge both DataFrames on 'timestamp' and 'SystemCodeNumber'\n",
        "# This aligns prices from both models for the same parking lot and time\n",
        "merged_df = pd.merge(\n",
        "    baseline_df,\n",
        "    model3_df,\n",
        "    on=[\"timestamp\", \"SystemCodeNumber\"],\n",
        "    suffixes=(\"_baseline\", \"_model3\")  # Add suffixes to differentiate columns\n",
        ")\n",
        "\n",
        "# Calculate the price difference between the two models\n",
        "merged_df[\"price_diff\"] = merged_df[\"price_model3\"] - merged_df[\"price_baseline\"]\n",
        "\n",
        "# Save the merged and annotated output to a new CSV\n",
        "merged_df.to_csv(\"model1_vs_model3_comparison.csv\", index=False)\n",
        "\n",
        "# Display a success message and preview of the output\n",
        "print(\"Comparison completed. Sample output:\")\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "id": "_7vj8qoeXlXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Price Comparison Plot: Model 1 vs Model 2 vs Model 3\n",
        "This script compares pricing predictions from all three models\n",
        "for a selected parking lot over time using a line plot.\n"
      ],
      "metadata": {
        "id": "5N5gUGfoYSN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Load model outputs from CSV files\n",
        "model1_df = pd.read_csv(\"baseline_output.csv\")           # Model 1: Baseline\n",
        "model2_df = pd.read_csv(\"model2_demand_output.csv\")      # Model 2: Demand-based\n",
        "model3_df = pd.read_csv(\"model3_output.csv\")             # Model 3: Geo + Demand\n",
        "\n",
        "# Rename 'lot' to 'SystemCodeNumber' in Model 1 and 2 for consistent merging\n",
        "for df in [model1_df, model2_df]:\n",
        "    if 'lot' in df.columns:\n",
        "        df.rename(columns={'lot': 'SystemCodeNumber'}, inplace=True)\n",
        "\n",
        "# Convert timestamp strings to datetime objects for plotting\n",
        "for df in [model1_df, model2_df, model3_df]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Rename price columns to distinguish between models\n",
        "model1_df.rename(columns={\"price\": \"price_model1\"}, inplace=True)\n",
        "model2_df.rename(columns={\"price\": \"price_model2\"}, inplace=True)\n",
        "model3_df.rename(columns={\"price\": \"price_model3\"}, inplace=True)\n",
        "\n",
        "# Merge all three model outputs on timestamp and lot number\n",
        "merged_df = model1_df.merge(model2_df, on=[\"timestamp\", \"SystemCodeNumber\"], how=\"inner\")\n",
        "merged_df = merged_df.merge(model3_df, on=[\"timestamp\", \"SystemCodeNumber\"], how=\"inner\")\n",
        "\n",
        "# Focus on a specific parking lot to reduce clutter in the plot\n",
        "lot = \"BHMBCCMKT01\"\n",
        "filtered = merged_df[merged_df[\"SystemCodeNumber\"] == lot].sort_values(\"timestamp\")\n",
        "\n",
        "# --- Plotting Section ---\n",
        "\n",
        "# Set up figure size\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot price lines for all 3 models with distinct styles\n",
        "plt.plot(filtered[\"timestamp\"], filtered[\"price_model1\"], label=\"Model 1 (Baseline)\", linestyle=\"--\", color=\"blue\", marker='o')\n",
        "plt.plot(filtered[\"timestamp\"], filtered[\"price_model2\"], label=\"Model 2 (Demand-Based)\", linestyle=\"-.\", color=\"orange\", marker='o')\n",
        "plt.plot(filtered[\"timestamp\"], filtered[\"price_model3\"], label=\"Model 3 (Geo + Demand)\", linestyle=\"-\", color=\"green\", marker='o')\n",
        "\n",
        "# Format the x-axis with date labels\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add axis labels and title\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Price ($)\")\n",
        "plt.title(f\"Price Comparison for Lot: {lot}\")\n",
        "\n",
        "# Enable grid and legend for clarity\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RJtBWgTTYO33"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}